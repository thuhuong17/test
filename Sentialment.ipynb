{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dcbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab999caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7713f86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53067</th>\n",
       "      <td>Samsung Baby Care Washer, Stainless Platinum, ...</td>\n",
       "      <td>My infant goes to a really crappy daycare, and...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53068</th>\n",
       "      <td>Mud Pie Milestone Stickers, Boy</td>\n",
       "      <td>Pretty please open and inspect these stickers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53069</th>\n",
       "      <td>Best BIB for Baby - Soft Bib (Pink-Elephant)</td>\n",
       "      <td>Great 5-Star Product but An Obvious knock-off ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53070</th>\n",
       "      <td>Bouncy&amp;reg; Inflatable Real Feel Hopping Cow</td>\n",
       "      <td>When I received the item my initial thought wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53071</th>\n",
       "      <td>Maxboost iPhone 5S/5 Case - Protective Snap-on...</td>\n",
       "      <td>I got this case in the mail today, it came on ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53072 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      Stop Pacifier Sucking without tears with Thumb...   \n",
       "1        Nature's Lullabies Second Year Sticker Calendar   \n",
       "2        Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                            Lamaze Peekaboo, I Love You   \n",
       "4      SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "...                                                  ...   \n",
       "53067  Samsung Baby Care Washer, Stainless Platinum, ...   \n",
       "53068                    Mud Pie Milestone Stickers, Boy   \n",
       "53069       Best BIB for Baby - Soft Bib (Pink-Elephant)   \n",
       "53070       Bouncy&reg; Inflatable Real Feel Hopping Cow   \n",
       "53071  Maxboost iPhone 5S/5 Case - Protective Snap-on...   \n",
       "\n",
       "                                                  review  rating  sentiment  \n",
       "0      All of my kids have cried non-stop when I trie...       5          1  \n",
       "1      We wanted to get something to keep track of ou...       5          1  \n",
       "2      My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3      One of baby's first and favorite books, and it...       4          1  \n",
       "4      Very cute interactive book! My son loves this ...       5          1  \n",
       "...                                                  ...     ...        ...  \n",
       "53067  My infant goes to a really crappy daycare, and...       1         -1  \n",
       "53068  Pretty please open and inspect these stickers ...       1         -1  \n",
       "53069  Great 5-Star Product but An Obvious knock-off ...       1         -1  \n",
       "53070  When I received the item my initial thought wa...       2         -1  \n",
       "53071  I got this case in the mail today, it came on ...       2         -1  \n",
       "\n",
       "[53072 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1bed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         object\n",
       "review       object\n",
       "rating        int64\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c23161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          90\n",
       "review       241\n",
       "rating         0\n",
       "sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df308c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b88214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "review       0\n",
       "rating       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba63a60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52741, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b647791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number od positive reviews: 26380\n",
      "Number od negative reviews: 26361\n"
     ]
    }
   ],
   "source": [
    "print(\"Number od positive reviews:\", sum(products[\"sentiment\"]==1))\n",
    "print(\"Number od negative reviews:\", sum(products[\"sentiment\"]==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46886527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "with open(\"important_words.json\", \"r\") as f:\n",
    "    important_words = json.load(f)\n",
    "print(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c2a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "714675ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We found this book at a rummage sale and found it to be so useful, especially when several people are helping with the baby (ex: visiting family, etc.)  We loved it so much that I\\'ve bought another one and have almost filled that one too.  I like having the room to write things about our baby\\'s day and development, plus use the \"Notes\" section to write some story, etc.  It also helps \"Dad\" see what has happened that day and feels more connected.  I will be buying another one soon!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"review\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e5fa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{83: 80, 44: None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Pam!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Hello, Sam!\"\n",
    "table = txt.maketrans(\"S\", \"P\", \",\")\n",
    "print(table)\n",
    "txt.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19b56e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48af8084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Pam'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = txt.maketrans(\"S\", \"P\", string.punctuation)\n",
    "txt.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6dc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac386f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"review_clean\"] = products[\"review\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcdbc312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53067</th>\n",
       "      <td>Samsung Baby Care Washer, Stainless Platinum, ...</td>\n",
       "      <td>My infant goes to a really crappy daycare, and...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>My infant goes to a really crappy daycare and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53068</th>\n",
       "      <td>Mud Pie Milestone Stickers, Boy</td>\n",
       "      <td>Pretty please open and inspect these stickers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pretty please open and inspect these stickers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53069</th>\n",
       "      <td>Best BIB for Baby - Soft Bib (Pink-Elephant)</td>\n",
       "      <td>Great 5-Star Product but An Obvious knock-off ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Great 5Star Product but An Obvious knockoff of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53070</th>\n",
       "      <td>Bouncy&amp;reg; Inflatable Real Feel Hopping Cow</td>\n",
       "      <td>When I received the item my initial thought wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>When I received the item my initial thought wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53071</th>\n",
       "      <td>Maxboost iPhone 5S/5 Case - Protective Snap-on...</td>\n",
       "      <td>I got this case in the mail today, it came on ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>I got this case in the mail today it came on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52741 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      Stop Pacifier Sucking without tears with Thumb...   \n",
       "1        Nature's Lullabies Second Year Sticker Calendar   \n",
       "2        Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                            Lamaze Peekaboo, I Love You   \n",
       "4      SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "...                                                  ...   \n",
       "53067  Samsung Baby Care Washer, Stainless Platinum, ...   \n",
       "53068                    Mud Pie Milestone Stickers, Boy   \n",
       "53069       Best BIB for Baby - Soft Bib (Pink-Elephant)   \n",
       "53070       Bouncy&reg; Inflatable Real Feel Hopping Cow   \n",
       "53071  Maxboost iPhone 5S/5 Case - Protective Snap-on...   \n",
       "\n",
       "                                                  review  rating  sentiment  \\\n",
       "0      All of my kids have cried non-stop when I trie...       5          1   \n",
       "1      We wanted to get something to keep track of ou...       5          1   \n",
       "2      My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3      One of baby's first and favorite books, and it...       4          1   \n",
       "4      Very cute interactive book! My son loves this ...       5          1   \n",
       "...                                                  ...     ...        ...   \n",
       "53067  My infant goes to a really crappy daycare, and...       1         -1   \n",
       "53068  Pretty please open and inspect these stickers ...       1         -1   \n",
       "53069  Great 5-Star Product but An Obvious knock-off ...       1         -1   \n",
       "53070  When I received the item my initial thought wa...       2         -1   \n",
       "53071  I got this case in the mail today, it came on ...       2         -1   \n",
       "\n",
       "                                            review_clean  \n",
       "0      All of my kids have cried nonstop when I tried...  \n",
       "1      We wanted to get something to keep track of ou...  \n",
       "2      My daughter had her 1st baby over a year ago S...  \n",
       "3      One of babys first and favorite books and it i...  \n",
       "4      Very cute interactive book My son loves this b...  \n",
       "...                                                  ...  \n",
       "53067  My infant goes to a really crappy daycare and ...  \n",
       "53068  Pretty please open and inspect these stickers ...  \n",
       "53069  Great 5Star Product but An Obvious knockoff of...  \n",
       "53070  When I received the item my initial thought wa...  \n",
       "53071  I got this case in the mail today it came on t...  \n",
       "\n",
       "[52741 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "797e7354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This product was exactly what I needed I could not find one locally  my only choice was to drive to another larger town'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"review_clean\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e172fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "53067    2\n",
       "53068    0\n",
       "53069    0\n",
       "53070    0\n",
       "53071    0\n",
       "Name: review_clean, Length: 52741, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"review_clean\"].str.count(\"baby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fa89d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "print(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "242c50a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11664\\3348184822.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products[word] = products[\"review_clean\"].str.count(word)\n"
     ]
    }
   ],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products[\"review_clean\"].str.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4c2826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53067</th>\n",
       "      <td>Samsung Baby Care Washer, Stainless Platinum, ...</td>\n",
       "      <td>My infant goes to a really crappy daycare, and...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>My infant goes to a really crappy daycare and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53068</th>\n",
       "      <td>Mud Pie Milestone Stickers, Boy</td>\n",
       "      <td>Pretty please open and inspect these stickers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pretty please open and inspect these stickers ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53069</th>\n",
       "      <td>Best BIB for Baby - Soft Bib (Pink-Elephant)</td>\n",
       "      <td>Great 5-Star Product but An Obvious knock-off ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Great 5Star Product but An Obvious knockoff of...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53070</th>\n",
       "      <td>Bouncy&amp;reg; Inflatable Real Feel Hopping Cow</td>\n",
       "      <td>When I received the item my initial thought wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>When I received the item my initial thought wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53071</th>\n",
       "      <td>Maxboost iPhone 5S/5 Case - Protective Snap-on...</td>\n",
       "      <td>I got this case in the mail today, it came on ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>I got this case in the mail today it came on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52741 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      Stop Pacifier Sucking without tears with Thumb...   \n",
       "1        Nature's Lullabies Second Year Sticker Calendar   \n",
       "2        Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                            Lamaze Peekaboo, I Love You   \n",
       "4      SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "...                                                  ...   \n",
       "53067  Samsung Baby Care Washer, Stainless Platinum, ...   \n",
       "53068                    Mud Pie Milestone Stickers, Boy   \n",
       "53069       Best BIB for Baby - Soft Bib (Pink-Elephant)   \n",
       "53070       Bouncy&reg; Inflatable Real Feel Hopping Cow   \n",
       "53071  Maxboost iPhone 5S/5 Case - Protective Snap-on...   \n",
       "\n",
       "                                                  review  rating  sentiment  \\\n",
       "0      All of my kids have cried non-stop when I trie...       5          1   \n",
       "1      We wanted to get something to keep track of ou...       5          1   \n",
       "2      My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3      One of baby's first and favorite books, and it...       4          1   \n",
       "4      Very cute interactive book! My son loves this ...       5          1   \n",
       "...                                                  ...     ...        ...   \n",
       "53067  My infant goes to a really crappy daycare, and...       1         -1   \n",
       "53068  Pretty please open and inspect these stickers ...       1         -1   \n",
       "53069  Great 5-Star Product but An Obvious knock-off ...       1         -1   \n",
       "53070  When I received the item my initial thought wa...       2         -1   \n",
       "53071  I got this case in the mail today, it came on ...       2         -1   \n",
       "\n",
       "                                            review_clean  baby  one  great  \\\n",
       "0      All of my kids have cried nonstop when I tried...     0    0      1   \n",
       "1      We wanted to get something to keep track of ou...     0    1      0   \n",
       "2      My daughter had her 1st baby over a year ago S...     1    2      0   \n",
       "3      One of babys first and favorite books and it i...     1    0      0   \n",
       "4      Very cute interactive book My son loves this b...     0    0      1   \n",
       "...                                                  ...   ...  ...    ...   \n",
       "53067  My infant goes to a really crappy daycare and ...     2    0      0   \n",
       "53068  Pretty please open and inspect these stickers ...     0    0      0   \n",
       "53069  Great 5Star Product but An Obvious knockoff of...     0    2      0   \n",
       "53070  When I received the item my initial thought wa...     0    1      0   \n",
       "53071  I got this case in the mail today it came on t...     0    0      0   \n",
       "\n",
       "       love  use  ...  seems  picture  completely  wish  buying  babies  won  \\\n",
       "0         0    0  ...      0        0           0     0       0       0    0   \n",
       "1         0    0  ...      0        0           0     0       0       0    0   \n",
       "2         0    0  ...      0        0           0     0       0       0    1   \n",
       "3         0    1  ...      0        0           0     0       0       0    0   \n",
       "4         1    0  ...      0        0           0     0       0       1    0   \n",
       "...     ...  ...  ...    ...      ...         ...   ...     ...     ...  ...   \n",
       "53067     0    0  ...      0        0           0     0       0       0    0   \n",
       "53068     0    0  ...      0        0           0     0       0       0    0   \n",
       "53069     0    1  ...      0        0           0     0       0       0    1   \n",
       "53070     0    1  ...      0        0           0     0       0       0    0   \n",
       "53071     0    0  ...      0        2           1     0       0       0    0   \n",
       "\n",
       "       tub  almost  either  \n",
       "0        0       0       0  \n",
       "1        0       0       0  \n",
       "2        0       0       0  \n",
       "3        0       0       0  \n",
       "4        0       0       0  \n",
       "...    ...     ...     ...  \n",
       "53067    0       0       0  \n",
       "53068    0       0       0  \n",
       "53069    0       0       0  \n",
       "53070    0       0       0  \n",
       "53071    0       0       0  \n",
       "\n",
       "[52741 rows x 198 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea12af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, validate_data = train_test_split(products, test_size=0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4eb339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42192, 198)\n",
      "(10549, 198)\n",
      "(52741, 198)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(validate_data.shape)\n",
    "print(products.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dddb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, fearures, label):\n",
    "    df[\"intercept\"] = 1\n",
    "    fearures = [\"intercept\"] + fearures\n",
    "    \n",
    "    feature_matrix = df[fearures].values\n",
    "    label_array = df[label].values\n",
    "    return (fearure_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "817ff76a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fearure_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fearure_matrix, sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_numpy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportant_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m fearure_matrix\u001b[38;5;241m.\u001b[39mshape\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mget_numpy_data\u001b[1;34m(df, fearures, label)\u001b[0m\n\u001b[0;32m      5\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m df[fearures]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m label_array \u001b[38;5;241m=\u001b[39m df[label]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mfearure_matrix\u001b[49m, label_array)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fearure_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "fearure_matrix, sentiment = get_numpy_data(train_data, important_words, \"sentiment\")\n",
    "fearure_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "073a9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(coefficients, feature_matrix):\n",
    "    predictions = 1/(1+np.exp(-np.dot(coefficients, feature_matrix)))\n",
    "    return predictionsfeature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e350ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feartures):\n",
    "    derivative = sum(np,dot(errors, features))\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaef5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likehood(fearure_matrix, sentiment, coefficents):\n",
    "    isone = (sentiment == 1)\n",
    "    dotfc = np.dot(fearture_matrix, coefficients)\n",
    "    lnexp = np.log(1+np.exp(-dotfc))\n",
    "    mask = np.isinf(lnexp)\n",
    "    lnexp[mask]=-dotfc[mask]\n",
    "    ll = sum((isone - 1) * dotfc -lnexp)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "679796e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2041889051.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [34]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def logistic_regression(fearure_matrix, sentiment, initial_coefficients, step_size = 1)\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(fearure_matrix, sentiment, initial_coefficients, step_size = 1)\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    for itr in range(max_iter):\n",
    "        predictions = predict_probability(coefficients, np.transpose(feature_matrix))\n",
    "        indicator = (sentimant == 1)\n",
    "        errors = indicator - predictions\n",
    "    for j in range(len(coefficients)):\n",
    "        coefficients[j] = coefficients[j] + step_size + feature_derivative(errors, feature_matrix [:, j])\n",
    "        if itr % 30 == 0:\n",
    "            ll = compute_log_likehood(feature_matrix, sentiment, coefficients)\n",
    "            print(f\"Iteration {itr}: Log-likehood is {ll}\")\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcc74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
